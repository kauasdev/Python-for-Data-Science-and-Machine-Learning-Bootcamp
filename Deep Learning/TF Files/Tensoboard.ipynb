{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b10e561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62feb690",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/cancer_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "307d05cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('benign_0__mal_1', axis=1).values\n",
    "y = df['benign_0__mal_1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11a220ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45579126",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=.25, random_state=101\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c6d99ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e8120a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f44b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e468bbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "335fa950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5db3d94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72f77e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    patience=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d79e7959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kauas/Desktop/Courses/udemy/Python for Data Science and Machine Learning Bootcamp/my codes/Deep Learning/TF Files'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ff3b51",
   "metadata": {},
   "source": [
    "## Creating the Tensorboard Callback\n",
    "\n",
    "O TensorBoard é uma ferramenta de visualização fornecida com o TensorFlow.\n",
    "\n",
    "Este retorno de chamada registra eventos para o TensorBoard, incluindo:\n",
    "* Gráficos de resumo de métricas\n",
    "* Visualização do gráfico de treinamento\n",
    "* Histogramas de ativação\n",
    "* Perfil amostrado\n",
    "\n",
    "Se você instalou o TensorFlow com pip, poderá\n",
    "para iniciar o TensorBoard na linha de comando:\n",
    "\n",
    "```sh\n",
    "tensorboard --logdir=path_to_your_logs\n",
    "```\n",
    "\n",
    "Você pode encontrar mais informações sobre o TensorBoard\n",
    "[aqui](https://www.tensorflow.org/tensorboard/).\n",
    "\n",
    "    Argumentos:\n",
    "        log_dir: o caminho do diretório onde salvar os arquivos de log a serem\n",
    "          analisado pelo TensorBoard.\n",
    "          \n",
    "        histogram_freq: frequência (em épocas) na qual calcular a ativação e\n",
    "          histogramas de peso para as camadas do modelo. Se definido como 0, os histogramas\n",
    "          não será computado. Os dados de validação (ou divisão) devem ser especificados para\n",
    "          visualizações de histograma.\n",
    "          \n",
    "        write_graph: se deseja visualizar o gráfico no TensorBoard. o arquivo de registro\n",
    "          pode se tornar muito grande quando write_graph é definido como True.\n",
    "          \n",
    "        write_images: se deseja gravar pesos de modelo para visualizar como imagem em\n",
    "          TensorBoard.\n",
    "          \n",
    "        update_freq: `'batch'` ou `'epoch'` ou integer. Ao usar `'lote'`,\n",
    "          grava as perdas e métricas no TensorBoard após cada lote. O mesmo\n",
    "          aplica-se a `'época'`. Se estiver usando um número inteiro, digamos `1000`, o\n",
    "          o retorno de chamada gravará as métricas e perdas no TensorBoard a cada 1.000\n",
    "          amostras. Observe que escrever com muita frequência no TensorBoard pode atrasar\n",
    "          seu treinamento.\n",
    "          \n",
    "        profile_batch: crie o perfil do lote para obter amostras das características de computação. Por\n",
    "          padrão, ele criará o perfil do segundo lote. Defina profile_batch=0 para\n",
    "          desative a criação de perfil. Deve ser executado no modo ansioso do TensorFlow.\n",
    "          \n",
    "        embeddings_freq: frequência (em épocas) em que as camadas de incorporação serão\n",
    "          ser visualizado. Se definido como 0, as incorporações não serão visualizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "768345a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61054e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-05-02--11:34'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().strftime('%Y-%m-%d--%H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddf34ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WINDOWS: Use \"logs\\\\fit\"\n",
    "# MACOS/LINUX: Use \"logs\\fit\"\n",
    "\n",
    "log_dir = 'logs/fit'\n",
    "\n",
    "# OPTIONAL: ADD A TIMESTAMP FOR UNIQUE FOLDER\n",
    "# timestamp = datetime.now().strftime(\"%Y-%m-%d--%H%M\")\n",
    "# log_directory = log_directory + '\\\\' + timestamp\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d--%H:%M')\n",
    "log_dir = f'{log_dir}/{timestamp}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9b921df",
   "metadata": {},
   "outputs": [],
   "source": [
    "??TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aac1cff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 11:40:20.204552: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2023-05-02 11:40:20.204590: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2023-05-02 11:40:20.223512: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "board = TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    "    update_freq='epoch',\n",
    "    profile_batch=2,\n",
    "    embeddings_freq=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10f2df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c07aa3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      " 1/14 [=>............................] - ETA: 8s - loss: 6.2119"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 11:43:13.373974: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2023-05-02 11:43:13.373996: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2023-05-02 11:43:13.382160: I tensorflow/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2023-05-02 11:43:13.390182: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 33ms/step - loss: 5.5410 - val_loss: 1.6324\n",
      "Epoch 2/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 3.9875 - val_loss: 1.1598\n",
      "Epoch 3/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 3.1459 - val_loss: 0.9746\n",
      "Epoch 4/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.9647 - val_loss: 0.9539\n",
      "Epoch 5/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.9425 - val_loss: 0.9081\n",
      "Epoch 6/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 2.9574 - val_loss: 0.9026\n",
      "Epoch 7/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 2.3483 - val_loss: 0.8808\n",
      "Epoch 8/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 2.5736 - val_loss: 0.8408\n",
      "Epoch 9/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 2.1915 - val_loss: 0.8095\n",
      "Epoch 10/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.2372 - val_loss: 0.7878\n",
      "Epoch 11/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.1185 - val_loss: 0.7868\n",
      "Epoch 12/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1.9233 - val_loss: 0.8149\n",
      "Epoch 13/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1.7837 - val_loss: 0.7478\n",
      "Epoch 14/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1.8893 - val_loss: 0.6709\n",
      "Epoch 15/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1.9263 - val_loss: 0.6447\n",
      "Epoch 16/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.6315 - val_loss: 0.6553\n",
      "Epoch 17/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1.3214 - val_loss: 0.6475\n",
      "Epoch 18/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1.5308 - val_loss: 0.6213\n",
      "Epoch 19/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1.3909 - val_loss: 0.5985\n",
      "Epoch 20/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.3877 - val_loss: 0.5925\n",
      "Epoch 21/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.0862 - val_loss: 0.5527\n",
      "Epoch 22/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1.1156 - val_loss: 0.5198\n",
      "Epoch 23/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.9988 - val_loss: 0.4827\n",
      "Epoch 24/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.9196 - val_loss: 0.4388\n",
      "Epoch 25/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.1823 - val_loss: 0.4964\n",
      "Epoch 26/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.3349 - val_loss: 0.4298\n",
      "Epoch 27/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.9832 - val_loss: 0.4126\n",
      "Epoch 28/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.9078 - val_loss: 0.4300\n",
      "Epoch 29/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.8723 - val_loss: 0.4247\n",
      "Epoch 30/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.9115 - val_loss: 0.4363\n",
      "Epoch 31/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.7384 - val_loss: 0.4410\n",
      "Epoch 32/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.8425 - val_loss: 0.4026\n",
      "Epoch 33/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.6793 - val_loss: 0.3501\n",
      "Epoch 34/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.8442 - val_loss: 0.3650\n",
      "Epoch 35/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.7931 - val_loss: 0.3478\n",
      "Epoch 36/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.7455 - val_loss: 0.3221\n",
      "Epoch 37/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.8306 - val_loss: 0.3112\n",
      "Epoch 38/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.7430 - val_loss: 0.2954\n",
      "Epoch 39/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.7592 - val_loss: 0.3060\n",
      "Epoch 40/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.6199 - val_loss: 0.3796\n",
      "Epoch 41/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.6174 - val_loss: 0.3454\n",
      "Epoch 42/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.6314 - val_loss: 0.3012\n",
      "Epoch 43/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.5544 - val_loss: 0.2928\n",
      "Epoch 44/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.5560 - val_loss: 0.2612\n",
      "Epoch 45/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.6983 - val_loss: 0.3124\n",
      "Epoch 46/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.6670 - val_loss: 0.4757\n",
      "Epoch 47/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.7581 - val_loss: 0.4157\n",
      "Epoch 48/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.8418 - val_loss: 0.3298\n",
      "Epoch 49/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.6352 - val_loss: 0.2880\n",
      "Epoch 50/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.5652 - val_loss: 0.2694\n",
      "Epoch 51/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.7940 - val_loss: 0.2684\n",
      "Epoch 52/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.6676 - val_loss: 0.2644\n",
      "Epoch 53/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.5475 - val_loss: 0.2659\n",
      "Epoch 54/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.5749 - val_loss: 0.3176\n",
      "Epoch 55/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.5531 - val_loss: 0.2534\n",
      "Epoch 56/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.6254 - val_loss: 0.3160\n",
      "Epoch 57/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.6124 - val_loss: 0.2948\n",
      "Epoch 58/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.5366 - val_loss: 0.2969\n",
      "Epoch 59/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.5717 - val_loss: 0.2854\n",
      "Epoch 60/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.6041 - val_loss: 0.2738\n",
      "Epoch 61/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.6380 - val_loss: 0.2821\n",
      "Epoch 62/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4999 - val_loss: 0.2855\n",
      "Epoch 63/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4864 - val_loss: 0.2195\n",
      "Epoch 64/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4327 - val_loss: 0.2914\n",
      "Epoch 65/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4596 - val_loss: 0.2819\n",
      "Epoch 66/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4437 - val_loss: 0.2777\n",
      "Epoch 67/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.5086 - val_loss: 0.2816\n",
      "Epoch 68/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4265 - val_loss: 0.2720\n",
      "Epoch 69/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4115 - val_loss: 0.2125\n",
      "Epoch 70/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.5693 - val_loss: 0.2975\n",
      "Epoch 71/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4513 - val_loss: 0.2810\n",
      "Epoch 72/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4852 - val_loss: 0.2471\n",
      "Epoch 73/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4474 - val_loss: 0.2204\n",
      "Epoch 74/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4278 - val_loss: 0.2856\n",
      "Epoch 75/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4206 - val_loss: 0.2813\n",
      "Epoch 76/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4402 - val_loss: 0.2706\n",
      "Epoch 77/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4641 - val_loss: 0.2618\n",
      "Epoch 78/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3938 - val_loss: 0.2565\n",
      "Epoch 79/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4559 - val_loss: 0.2694\n",
      "Epoch 80/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.4536 - val_loss: 0.2673\n",
      "Epoch 81/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3894 - val_loss: 0.2580\n",
      "Epoch 82/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4914 - val_loss: 0.2493\n",
      "Epoch 83/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4169 - val_loss: 0.1991\n",
      "Epoch 84/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4268 - val_loss: 0.2181\n",
      "Epoch 85/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3862 - val_loss: 0.1982\n",
      "Epoch 86/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4075 - val_loss: 0.1840\n",
      "Epoch 87/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4630 - val_loss: 0.1740\n",
      "Epoch 88/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3824 - val_loss: 0.1641\n",
      "Epoch 89/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4596 - val_loss: 0.1817\n",
      "Epoch 90/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4870 - val_loss: 0.1837\n",
      "Epoch 91/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3649 - val_loss: 0.1754\n",
      "Epoch 92/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4202 - val_loss: 0.2463\n",
      "Epoch 93/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.5161 - val_loss: 0.2357\n",
      "Epoch 94/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3967 - val_loss: 0.2302\n",
      "Epoch 95/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4536 - val_loss: 0.2341\n",
      "Epoch 96/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3519 - val_loss: 0.2307\n",
      "Epoch 97/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4958 - val_loss: 0.2229\n",
      "Epoch 98/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3637 - val_loss: 0.2189\n",
      "Epoch 99/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3888 - val_loss: 0.2221\n",
      "Epoch 100/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3889 - val_loss: 0.2178\n",
      "Epoch 101/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4043 - val_loss: 0.2310\n",
      "Epoch 102/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4336 - val_loss: 0.2312\n",
      "Epoch 103/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3531 - val_loss: 0.2240\n",
      "Epoch 104/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4261 - val_loss: 0.1680\n",
      "Epoch 105/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3090 - val_loss: 0.1757\n",
      "Epoch 106/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3916 - val_loss: 0.1692\n",
      "Epoch 107/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2313 - val_loss: 0.2266\n",
      "Epoch 108/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3654 - val_loss: 0.2158\n",
      "Epoch 109/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3059 - val_loss: 0.2096\n",
      "Epoch 110/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2374 - val_loss: 0.2078\n",
      "Epoch 111/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3275 - val_loss: 0.2060\n",
      "Epoch 112/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3896 - val_loss: 0.2057\n",
      "Epoch 113/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3620 - val_loss: 0.2087\n",
      "Epoch 113: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2363af9bd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=X_train, y=y_train,\n",
    "    epochs=600,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=1,\n",
    "    callbacks=[early_stop, board]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e962bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21c23edc",
   "metadata": {},
   "source": [
    "Tensorboard will run locally in your browser at [http://localhost:6006/](http://localhost:6006/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "789b2b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/fit/2023-05-02--11:37\n"
     ]
    }
   ],
   "source": [
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcf9ebd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kauas/Desktop/Courses/udemy/Python for Data Science and Machine Learning Bootcamp/my codes/Deep Learning/TF Files'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2845b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-02 11:44:49.456072: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "E0502 11:44:51.116488 140090824527872 application.py:125] Failed to load plugin WhatIfToolPluginLoader.load; ignoring it.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kauas/.local/lib/python3.10/site-packages/tensorboard/backend/application.py\", line 123, in TensorBoardWSGIApp\n",
      "    plugin = loader.load(context)\n",
      "  File \"/home/kauas/.local/lib/python3.10/site-packages/tensorboard_plugin_wit/wit_plugin_loader.py\", line 57, in load\n",
      "    from tensorboard_plugin_wit.wit_plugin import WhatIfToolPlugin\n",
      "  File \"/home/kauas/.local/lib/python3.10/site-packages/tensorboard_plugin_wit/wit_plugin.py\", line 40, in <module>\n",
      "    from tensorboard_plugin_wit._utils import common_utils\n",
      "  File \"/home/kauas/.local/lib/python3.10/site-packages/tensorboard_plugin_wit/_utils/common_utils.py\", line 17, in <module>\n",
      "    from tensorboard_plugin_wit._vendor.tensorflow_serving.apis import classification_pb2\n",
      "  File \"/home/kauas/.local/lib/python3.10/site-packages/tensorboard_plugin_wit/_vendor/tensorflow_serving/apis/classification_pb2.py\", line 15, in <module>\n",
      "    from tensorboard_plugin_wit._vendor.tensorflow_serving.apis import input_pb2 as tensorflow__serving_dot_apis_dot_input__pb2\n",
      "  File \"/home/kauas/.local/lib/python3.10/site-packages/tensorboard_plugin_wit/_vendor/tensorflow_serving/apis/input_pb2.py\", line 37, in <module>\n",
      "    _descriptor.FieldDescriptor(\n",
      "  File \"/home/kauas/.local/lib/python3.10/site-packages/google/protobuf/descriptor.py\", line 561, in __new__\n",
      "    _message.Message._CheckCalledFromGeneratedFile()\n",
      "TypeError: Descriptors cannot not be created directly.\n",
      "If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\n",
      "If you cannot immediately regenerate your protos, some other possible workarounds are:\n",
      " 1. Downgrade the protobuf package to 3.20.x or lower.\n",
      " 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n",
      "\n",
      "More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.12.2 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir logs/fit/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc32b057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
